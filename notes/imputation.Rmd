---
title: "Imputation with Amelia"
author: "Eric R. Scott"
date: "2020-07-21"
output: 
  html_notebook: 
    highlight: kate
    theme: yeti
    toc: yes
    toc_float: yes
    number_sections: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(here)
library(conflicted)
library(tsibble)
library(lubridate)
library(janitor)
library(Amelia)
library(parallel)
library(furrr)

conflict_prefer("filter", "dplyr")
conflict_prefer("lag", "dplyr")

future::plan("multisession")
```

*Last compiled: `r Sys.Date()`*


# TODO:

- Add additional weather data (ETo)
- Apply to entire dataset


# Purpose

Explore options for imputation of missing values.  In earlier versions of this document, I explored several options for imputation.  The `mice` package does multiple, multivariate imputation but it performed worse than simple methods like just using the mean.  The `mtsdi` package is for multivariate timeseries data, but it was too slow to be useable and poorly documented.  `Amelia` is well documented, and has functions to work with cross-sectional timeseries data.  It seems flexible, fast, and has built-in diagnostic features.

# Load & Wrangle Data

Because of the high degree of missingness in the BDFFP data, I'll combine a few sites into "clusters". The `Amelia` docs suggest using more variables rather than fewer, as it will increase the predictive power of the imputation algorithm. I'll therefore combine the BDFFP data with GPCC gridded data and Manaus station data (including variables besides precip). 

```{r data, echo=TRUE}
bdffp <- read_csv(here("data_cleaned", "daily_precip.csv"))
sa <- read_csv(here("data_cleaned", "sa_daily_1x1.csv"))
xa <- read_csv(here("data_cleaned", "xavier_daily_0.25x0.25.csv"))
manaus <- read_csv(here("data_cleaned", "manaus_weather.csv"))
min(bdffp$date)
```

## Remove accumulations

I'll remove ALL accumulations for an initial test and impute those values.  `Amelia` has the ability to take informative priors about individual observations, so in the future maybe I can use accumulated values to inform preceeding `NA`s.

```{r}
bdffp2 <-
  bdffp %>% 
  filter(!flag %in% c("A", "U"))
```

## Make wide

I'm going to treat each site as a variable so `Amelia` can take advantage of information from all the sites. For that, I need a wide dataset.

```{r}
bdffp_wide <- 
  bdffp2 %>% 
  #complete all the dates
  as_tsibble(key = site, index = date) %>% 
  fill_gaps() %>% 
  select(date, site, precip) %>% 
  as_tibble() %>% 
  pivot_wider(names_from = site, values_from = precip) %>% 
  clean_names()
```

## Add additional data sources

```{r}
xa_wide <-
  xa %>% 
  mutate(xa_latlon = paste(lat, lon, sep = ", "), lat = NULL, lon = NULL) %>% 
  pivot_wider(names_from = xa_latlon, values_from = c(precip, eto)) %>%
  clean_names()
```


I'll join and remove a few variables with weird distributions

```{r}
full_wide <-
  left_join(bdffp_wide, rename(manaus, manaus = precip), by = "date") %>%
  left_join(select(sa, date, sa = precip), by = "date") %>% 
  left_join(xa_wide, by = "date") %>% 
  mutate(year = year(date), doy = yday(date)) %>%
  select(year, doy, everything()) %>%
  select(-temp_max, -temp_min, -sun_time)
```


## Site Clusters

Use these sites:

1. dimona
2. Porto alegre
3. colosso_clust = Colosso, florestal, cabo frio, gaviao
4. km_clust = km37, km41

```{r}
full_wide2 <- 
  full_wide %>% 
  rowwise() %>% 
  mutate(colosso_clust = mean(c(colosso, florestal, cabo_frio, gaviao), na.rm = TRUE),
         km_clust = mean(c(km37, km41), na.rm = TRUE)) %>% 
  mutate(across(colosso_clust:km_clust, ~ifelse(is.nan(.x), NA, .x))) %>% 
  select(-cabo_frio, -colosso, -florestal, -gaviao, -km37, -km41)
```


# Impute with Amelia II

## Test data

Make a data frame for testing that is a subset of a few years.  I'll also make on that only has precip data in it, for testing.

```{r}
slice_wide <- full_wide2 %>% filter(between(year, 1990, 2000)) %>% as.data.frame()
slice_precip <- slice_wide %>% select(year, doy, date:manaus, colosso_clust, km_clust)
```



## Simple

Only include sites at BDFFP and manaus station.  No lags or leads.

```{r}
set.seed(123)

imp_ts1 <- 
  future_map(1:10, ~{
    amelia(
      slice_precip,
      p2s = 0,
      m = 1,
      ts = "doy",
      cs = "year",
      intercs = TRUE,
      polytime = 3,
      logs = c("dimona", "porto_alegre", "km_clust", "colosso_clust", "manaus"),
      idvars = c("date"),
      empri = .01 * nrow(slice_precip) #ridge penalty because of high degree of missingness
    )
  })

imp_ts1 <-
  ameliabind(
  imp_ts1[[1]],
  imp_ts1[[2]],
  imp_ts1[[3]],
  imp_ts1[[4]],
  imp_ts1[[5]],
  imp_ts1[[6]],
  imp_ts1[[7]],
  imp_ts1[[8]],
  imp_ts1[[9]],
  imp_ts1[[10]]
)
```


```{r}
imp_ts1
```

The chain lengths are fairly even, indicating that the ridge penalty is helping convergence.

## More vars

Now including all the variables.

```{r}
# hist(slice_wide$eto_2_375_59_625)
# hist(slice_wide$eto_2_375_59_625 %>% log())
# hist(slice_wide$eto_2_375_59_625 %>% sqrt())


all_cols <- colnames(select(slice_wide, -year, -doy, -date))

#eto normality improved by sqrt
sqrt_cols <- colnames(slice_wide %>% select(starts_with("eto_")))

#variables with log-normal-ish distributions
log_cols <- all_cols[!all_cols %in% c("rh", "temp_mean", sqrt_cols)]

set.seed(123)
imp_ts2 <-
  future_map(1:10, ~{
    amelia(
      slice_wide,
      m = 1,
      p2s = 0,
      ts = "doy",
      cs = "year",
      intercs = TRUE,
      polytime = 3,
      logs = log_cols,
      sqrts = sqrt_cols,
      idvars = c("date"),
      empri = .01 * nrow(slice_wide) #ridge penalty because of high degree of missingness
    )
  })
imp_ts2 <- ameliabind(
  imp_ts2[[1]],
  imp_ts2[[2]],
  imp_ts2[[3]],
  imp_ts2[[4]],
  imp_ts2[[5]],
  imp_ts2[[6]],
  imp_ts2[[7]],
  imp_ts2[[8]],
  imp_ts2[[9]],
  imp_ts2[[10]]
) 
```
```{r}
imp_ts2
```

## Add lags and leads
Of only ETo?


```{r}
set.seed(123)
imp_ts3 <-
  future_map(1:10, ~{
    amelia(
      slice_wide,
      m = 1,
      p2s = 0,
      ts = "doy",
      cs = "year",
      intercs = TRUE,
      polytime = 3,
      leads = sqrt_cols,
      lags = sqrt_cols,
      logs = log_cols,
      sqrts = sqrt_cols,
      idvars = c("date"),
      empri = .01 * nrow(slice_wide) #ridge penalty because of high degree of missingness
    )
  })
imp_ts3 <- ameliabind(
  imp_ts3[[1]],
  imp_ts3[[2]],
  imp_ts3[[3]],
  imp_ts3[[4]],
  imp_ts3[[5]],
  imp_ts3[[6]],
  imp_ts3[[7]],
  imp_ts3[[8]],
  imp_ts3[[9]],
  imp_ts3[[10]]
) 
```
```{r}
imp_ts3
```

# Diagnostics

## Compare distributions
These plots just compare distributions of observed and imputed data.  Observed = blue, imputed = red

```{r}
plot(imp_ts1)
plot(imp_ts2, which.vars = c("dimona", "porto_alegre", "km_clust", "colosso_clust"))
plot(imp_ts3, which.vars = c("dimona", "porto_alegre", "km_clust", "colosso_clust"))
```
Huh, here it seems like imputation tends to overestimate precipitation possibly.  It seems odd to me that the greatest mismatch between observed and imputed is in `km_clust` which has the lowest degree of missingness.

## Dispersion test

This diagnostic checks if starting values are likely to effect convergence.  All lines should end up converging at the same place.

```{r}
# disperse(imp_ts1, dims = 1, m = 10)
# disperse(imp_ts2, dims = 1, m = 10)
disperse(imp_ts3, dims = 1, m = 10)
```

The models with more variables are not converging quickly, but they are all converging on the same value, so that's good.  It's possible that this won't be a problem once the full data set is used because there will be many more observations.

## Overimputation

This test removes an observation that is known, imputes it, then plots the observed vs. imputed.  A perfect result would be points that follow the line perfectly.  Color represents row-wise missingness. (rows with fewer co-variates probably should perform worse).

```{r}
overimpute(imp_ts1, var = "dimona")
overimpute(imp_ts2, var = "dimona")
overimpute(imp_ts3, var = "dimona")
```

They actually seem fairly equivalent.  Imputation tends to underestimate actual precip, but 90% confidence intervals mostly overlap line.  I wonder if this is affected by the ridge penalty?

```{r}
overimpute(imp_ts1, var = "km_clust")
overimpute(imp_ts2, var = "km_clust")
overimpute(imp_ts3, var = "km_clust")
```

Can't tell, but maybe adding lags helped? Adding more variables helps more than adding lags and leads.

## Timeseries Plots

We can also pick a few year/site combos to compare the 4 methods

```{r}
tscsPlot(imp_ts1, cs ="1995", var = "km_clust", ylim = c(0,150))
tscsPlot(imp_ts2, cs ="1995", var = "km_clust", ylim = c(0,150))
tscsPlot(imp_ts3, cs ="1995", var = "km_clust", ylim = c(0,150))
```

```{r}
tscsPlot(imp_ts1, cs ="1997", var = "dimona", ylim = c(0,150))
tscsPlot(imp_ts2, cs ="1997", var = "dimona", ylim = c(0,150))
tscsPlot(imp_ts3, cs ="1997", var = "dimona", ylim = c(0,150))
```

```{r}
tscsPlot(imp_ts1, cs ="1997", var = "colosso_clust", ylim = c(0,150))
tscsPlot(imp_ts2, cs ="1997", var = "colosso_clust", ylim = c(0,150))
tscsPlot(imp_ts3, cs ="1997", var = "colosso_clust", ylim = c(0,150))
```

It doesn't seem like one of these methods is consistently better than others.

# Calculate SPI with imputed dataset

I want to apply the SPI calculation on all the BDFFP sites for all the multiple imputations, then combine them and look at the coefficient of variation or something to see how tight the estimates are.

Here's where I need to figure out how to use this data class.  Need to go back to the Amelia manual.

```{r}
class(imp_ts3)
names(imp_ts3$imputations)
# imp_ts3$imputations[[1]]
```


```{r}
imp_spi <- 
  map(imp_ts3$imputations, ~{
    .x %>% 
      select(date, dimona, porto_alegre, colosso_clust, km_clust) %>% 
      mutate(yearmonth = tsibble::yearmonth(date)) %>% 
      group_by(yearmonth) %>% 
      summarize(across(-date, ~sum(.x, na.rm = TRUE))) %>% 
      mutate(across(-yearmonth, ~as.numeric(SPEI::spi(.x, scale = 3)$fitted))) %>%
      filter(complete.cases(.))
  }) %>% 
  bind_rows(.id = "imp")

imp_spi_long <-
  imp_spi %>% 
  pivot_longer(dimona:km_clust, names_to = "site", values_to = "spi") %>% 
  mutate(date = as_date(yearmonth))

imp_mean <-
  imp_spi_long %>% 
  group_by(yearmonth, site) %>% 
  summarize(spi_mean = mean(spi)) %>% 
  mutate(date = as_date(yearmonth))
```

- spi <= -2.0 ~ "extreme",
- -2.0 < spi <= -1.5  ~ "severe",
- -1.5 < spi <= -1.0 ~ "moderate",
- -1.0 < spi <= 0 ~ "mild"

```{r}
spi_imp_plot <-
  ggplot(imp_spi_long, aes(x = date, y = spi)) +
  geom_rect(aes(xmin = min(date), xmax = max(date), ymin = -4.2, ymax = -2), fill = "red", alpha = 0.01) +
  geom_rect(aes(xmin = min(date), xmax = max(date), ymin = -2, ymax = -1.5), fill = "darkorange", alpha = 0.01) +
  geom_rect(aes(xmin = min(date), xmax = max(date), ymin = -1.5, ymax = -1), fill = "orange", alpha = 0.01) +
  geom_rect(aes(xmin = min(date), xmax = max(date), ymin = -1, ymax = 0), fill = "yellow", alpha = 0.01) +
  geom_line(aes(group = imp), alpha = 0.1) +
  geom_line(data = imp_mean, aes(x = date, y = spi_mean), color = "blue") +
  facet_wrap(~site) +
  scale_x_date(date_breaks = "2 years", date_labels = "%Y", expand = c(0,0)) +
  scale_y_continuous(limits = c(-4.2, 2), expand = c(0,0)) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "SPI calculated from multiply-imputed data", y = "SPI", x = "Date", caption = "Grey lines = individual imputations, blue line = mean, red = extreme, dark orange = severe, orange = moderate, yellow = mild")
spi_imp_plot
```

```{r}
ggsave(here("notes", "spi_imputed.png"), spi_imp_plot)
```

# Compare to replacement rules

```{r}
repl <- read_csv(here("data_cleaned", "mon_precip_spi_repl.csv"))

repl1 <-
  repl %>%
  separate(yearmonth, into = c("year", "month"), sep = " ") %>% 
  mutate(date = mdy(paste(month, "1,", year))) %>% 
  filter(between(date, min(imp_spi_long$date), max(imp_spi_long$date)))

repl2 <-
  repl1 %>%
  select(date, site, spi) %>% 
  pivot_wider(names_from = site, values_from = spi) %>% 
  rowwise() %>% 
  mutate(km_clust = mean(c(km37, km41), na.rm = TRUE),
         colosso_clust = mean(c(florestal, gaviao, cabo_frio, colosso))) %>% 
  select(date, colosso_clust, dimona, km_clust, porto_alegre) %>% 
  pivot_longer(-date, names_to = "site", values_to = "spi")
```


```{r}
spi_rules_plot <- 
  ggplot(repl2, aes(x = date, y = spi)) +
  geom_rect(aes(
    xmin = min(date),
    xmax = max(date),
    ymin = -4.2,
    ymax = -2
  ), fill = "red", alpha = 0.01) +
  geom_rect(aes(
    xmin = min(date),
    xmax = max(date),
    ymin = -2,
    ymax = -1.5
  ), fill = "darkorange", alpha = 0.01) +
  geom_rect(aes(
    xmin = min(date),
    xmax = max(date),
    ymin = -1.5,
    ymax = -1
  ), fill = "orange", alpha = 0.01) +
  geom_rect(aes(
    xmin = min(date),
    xmax = max(date),
    ymin = -1,
    ymax = 0
  ), fill = "yellow", alpha = 0.01) +
  geom_line(color = "blue") +
  facet_wrap( ~ site) +
  scale_x_date(date_breaks = "2 years", date_labels = "%Y", expand = c(0,0)) +
  scale_y_continuous(limits = c(-4.2, 2), expand = c(0,0)) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(
    title = "SPI calculated from replacement-rule data",
    y = "SPI",
    x = "Date",
    caption = "red = extreme, dark orange = severe, orange = moderate, yellow = mild"
  )

spi_rules_plot
```
```{r}
ggsave(here("notes", "spi_rules.png"), spi_rules_plot)
```

# SPEI

Use ETo from the gridded dataset and combine with precip values to calculate SPEI using `SPEI::spei()`

```{r}
x <- imp_ts3$imputations[[1]]
x
```

## Match sites to ETo grids

We have ETo from 3 0.25º x 0.25º grid cells:

From west to east, 60.125º W, 59.875º W, and 59.625º W

```{r}
#center points
sp::dd2dms(c(60.125, 59.875, 59.625))

#range for grid 1
sp::dd2dms(c(60.125 + 0.25/2, 60.125 - 0.25/2))
# only dimona

#range for grid 2
sp::dd2dms(c(59.875 + 0.25/2, 59.875 - 0.25/2))

#Porto Alegre, Colosso cluster

# Range for grid 3
sp::dd2dms(c(59.625 + 0.25/2, 59.625 - 0.25/2))
#km cluster
```

## Climatic balance

Calculate precip - ETo for each site

```{r}
imp_spei <-
  map(imp_ts3$imputations, function(x){
    x2 <-
      x %>% 
      mutate(cb_dimona = dimona - eto_2_375_60_125) %>% 
      mutate(across(.cols = c(porto_alegre, colosso_clust), .fns = ~.x - eto_2_375_59_875, .names = "cb_{col}")) %>% 
      mutate(cb_km_clust = km_clust - eto_2_375_59_625)
    x2 %>% 
      select(date, starts_with("cb_")) %>% 
      mutate(yearmonth = tsibble::yearmonth(date)) %>% 
      group_by(yearmonth) %>% 
      summarize(across(starts_with("cb_"), ~sum(.x, na.rm = TRUE))) %>% 
      mutate(across(-yearmonth, ~as.numeric(SPEI::spei(.x, scale = 3)$fitted))) %>%
      filter(complete.cases(.))
  }) %>% 
  bind_rows(.id = "imp")

imp_spei_long <-
  imp_spei %>% 
  pivot_longer(starts_with("cb_"), names_to = "site", values_to = "spei", names_prefix = "cb_") %>% 
  mutate(date = as_date(yearmonth))

imp_mean_spei <-
  imp_spei_long %>% 
  group_by(yearmonth, site) %>% 
  summarize(spei_mean = mean(spei)) %>% 
  mutate(date = as_date(yearmonth))

```


## Plot

```{r}
spei_imp_plot <-
  ggplot(imp_spei_long, aes(x = date, y = spei)) +
  geom_rect(aes(xmin = min(date), xmax = max(date), ymin = -4.2, ymax = -2), fill = "red", alpha = 0.01) +
  geom_rect(aes(xmin = min(date), xmax = max(date), ymin = -2, ymax = -1.5), fill = "darkorange", alpha = 0.01) +
  geom_rect(aes(xmin = min(date), xmax = max(date), ymin = -1.5, ymax = -1), fill = "orange", alpha = 0.01) +
  geom_rect(aes(xmin = min(date), xmax = max(date), ymin = -1, ymax = 0), fill = "yellow", alpha = 0.01) +
  geom_line(aes(group = imp), alpha = 0.1) +
  geom_line(data = imp_mean_spei, aes(x = date, y = spei_mean), color = "blue") +
  facet_wrap(~site) +
  scale_x_date(date_breaks = "2 years", date_labels = "%Y", expand = c(0,0)) +
  scale_y_continuous(limits = c(-4.2, 2), expand = c(0,0)) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "SPEI calculated from multiply-imputed precip and gridded ETo", y = "SPEI", x = "Date", caption = "Grey lines = individual imputations, blue line = mean, red = extreme, dark orange = severe, orange = moderate, yellow = mild")
spei_imp_plot
```
```{r}
ggsave(here("notes", "spei_imputed.png"), spei_imp_plot)
```


# Next Steps

## Spatially explicit imputation??

`Ameila` is not spatially explicit.  That is, it does not take distance between sites into account when imputing.  The CRAN Task View on missing data does list some packages for spatio-temporal imputation, but they look less developed than Ameila.

## Scale up

So far, I've only run the `Amelia` diagnostics on imputation from a small slice of the precip data.  I should run it on the full dataset and see how it performs.

## Tests to make sure SPI calcs are working right

Does my method work the same as supplying a multivariate timeseries to `spi()`?

`?spi()`:

>If it is a (univariate or multivariate) time series then the function cycle will be used to determine the position of each observation within the year (month), allowing the data to start in a month other than January.


```{r}
x <- imp_ts3$imputations[[1]]
x_mon <-
  x %>% 
  select(date, dimona, porto_alegre, colosso_clust, km_clust) %>% 
  mutate(yearmonth = tsibble::yearmonth(date)) %>% 
  group_by(yearmonth) %>% 
  summarize(across(-date, ~sum(.x, na.rm = TRUE))) %>% 
  slice(-1) #what if data starts not in January?

x_dplyr <-
  x_mon %>% 
  mutate(across(-yearmonth, ~as.numeric(SPEI::spi(.x, scale = 3)$fitted)))
```

Or...

```{r}
x_ts <-
  x_mon %>% 
  as_tsibble(index = yearmonth) %>%
  as.ts()

x_SPEI <-
  SPEI::spi(x_ts, scale = 3)$fitted %>%
  as_tsibble() %>% 
  pivot_wider(names_from = key, values_from = value) %>% 
  rename(yearmonth = index)

all_equal(x_dplyr, x_SPEI)
```


