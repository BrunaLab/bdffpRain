---
title: "Gridded data wrangling"
author: "Eric R. Scott"
date: "2020-08-12"
output: 
  html_notebook: 
    highlight: kate
    theme: yeti
    toc: yes
    toc_float: yes
    number_sections: yes
---

**TODO:**

- Explore usefulness of statistical downscaling of gridded data using the [rainfarmr](https://github.com/jhardenberg/rainfarmr) package

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(here)
library(conflicted)
conflict_prefer("filter", "dplyr")
conflict_prefer("select", "dplyr")
library(ncdf4)
library(raster)
library(lubridate)
library(sp)
```

*Last compiled: `r Sys.Date()`*

# GPCC
To browse datasets, visit https://psl.noaa.gov/thredds/catalog/Datasets/catalog.html Choose a dataset and get the OPENDAP url.
Here's how to download 1 year of data for the whole world

Starts at year 1891 goes through 2016

```{r}
gpcc <- nc_open("https://psl.noaa.gov/thredds/dodsC/Datasets/gpcc/full_v2018/precip.mon.total.v2018.nc")

names(gpcc$var)
names(gpcc$dim)

lat <- ncvar_get(gpcc, "lat")
lon <- ncvar_get(gpcc, "lon")
time <- ncvar_get(gpcc, "time") #"days since 1800-1-1 00:00:00"

time <- as_date(time, origin = ymd("1800-01-01"))
```

## Filter location and dates

I want to restrict this to a lat-lon near BDFFP and time that we have data for BDFFP

Lower-left corner = 02º30'00"S; 60º10'00"W
Upper-right corner = 02º15'00"S; 59º35'00"W

```{r}
(lat_min <- char2dms("2d15'S") %>% as.numeric())
(lat_max <- char2dms("02d30'S") %>% as.numeric())
(lon_min <- char2dms("60d10'W") %>% as.numeric())
(lon_max <- char2dms("59d35'W") %>% as.numeric())
```

This dataset uses 360º longitudes rather than negative numbers.  Next, find the index that matches these coords.

```{r}
lat_min_i <- which.min(abs(lat - lat_min))
lat_max_i <- lat_min_i + 1
lon_min_i <- which.min(abs(lon - (360 + lon_min)))
lon_max_i <- which.min(abs(lon - (360 + lon_max))) + 1
```


```{r}
lon[lon_min_i:lon_max_i] - 360
```
just the -60.25 and -59.75 are enough.  That spans from -60 to -59.5

```{r}
lat[lat_min_i:lat_max_i]
```

Just the -2.25 grid is enough since it would span -2 to -2.5

```{r}
tstart_i <- which(time == ymd("1987-09-01"))
tend_i <- which(time == ymd("2013-02-01"))
```


```{r}
precip <- ncvar_get(gpcc, "precip",
                    start = c(lon_min_i, lat_min_i, tstart_i), # c(lon, lat, time)
                    count = c(2, 1, tend_i - tstart_i + 1)  # c(lon, lat, time)
                    ) 
dim(precip)
```

rows are lon (-60.25, -59.75), columns are time
lat = -2.25


precip[lon, time]

## Tidy

Need to smoosh this array into a tidy dataframe with columns `lat`, `lon`, `date`, and `precip`.  I think.


```{r}
dimnames(precip) <- list(lon[lon_min_i:(lon_max_i-1)],
                         as.character(time[tstart_i:tend_i]))

out <-
  precip %>%
  as_tibble(rownames = "lon") %>% 
  pivot_longer(-lon, names_to = "date", values_to = "precip") %>% 
  add_column(lat = -2.25, .before = lon) %>% 
  mutate(lon = as.numeric(lon) - 360) %>% 
  select(date, lat, lon, precip) %>% 
  arrange(date)
out
```

```{r}
write_csv(out, here("data_cleaned", "gpcc_mon_tot_0.5x0.5.csv"))
```


```{r}
nc_close(gpcc)
```

# South America gridded data

This one is not available through OPENDAP as far as I can tell.  

Liebmann, Brant, and Dave Allured. “Daily Precipitation Grids for South America.” Bulletin of the American Meteorological Society 86, no. 11 (November 2005): 1567–70. https://doi.org/10.1175/BAMS-86-11-1567.

https://psl.noaa.gov/data/gridded/data.south_america_precip.html

## Download

```{r}
if (!file.exists(here("data_raw", "sa24.daily.1.nc"))) {
  download.file("ftp://ftp.cdc.noaa.gov/Datasets.other/south_america/sa24.daily.1.1940-2012.nc",
                here("data_raw", "sa24.daily.1.nc"))
}
```
```{r}
sa <- nc_open(here("data_raw", "sa24.daily.1.nc"))
```
```{r}
names(sa$var)
names(sa$dim)

lat <- ncvar_get(sa, "lat")
lon <- ncvar_get(sa, "lon")
time <- ncvar_get(sa, "time") #"days since 1800-1-1 00:00:00"

time <- as_date(time, origin = ymd("1800-01-01"))
```

## Filter location and time

I want the grid cell centered on -2 lat and -60 lon.  That will encompass all of BDFFP, I think.

```{r}
lat_i = which(lat == -2)
lon_i = which(lon == -60)
tstart_i <- which(time == ymd("1987-09-01"))
tend_i <- length(time)

precip <- ncvar_get(sa, "precip",
                    start = c(lon_i, lat_i, tstart_i), # c(lon, lat, time)
                    count = c(1, 1, tend_i - tstart_i + 1)  # c(lon, lat, time)
                    )
```

## Tidy

```{r}
dim(precip)
length(tstart_i:tend_i)

out <- tibble(date = time[tstart_i:tend_i], lat = -2, lon = -60, precip = precip)
out
write_csv(out, here("data_cleaned", "sa_daily_1x1.csv"))
```

# Xavier et al.

Gridded data that includes evapotranspiration, relative humidity, temperature, and precip.  Resolution is 0.25ºx0.25º.

Found here: http://careyking.com/data-downloads/

Xavier, Alexandre C., Carey W. King, and Bridget R. Scanlon. “Daily Gridded Meteorological Variables in Brazil (1980–2013).” International Journal of Climatology 36, no. 6 (2016): 2644–59. https://doi.org/10.1002/joc.4518.

The data comes in decade long files with one variable per file (UGH).  I'm using v2.1, not the most recent, but more complete than v2.2


## Merge NetCDF files

Merging the NetCDF files is going to be most easily done with a command line tool, `cdo`.  Info on installation here: https://code.mpimet.mpg.de/projects/cdo

```{r}
lon_min; lon_max
lat_min; lat_max
```

### Precip

This code filters each file for only the relevant grid cells, then merges them and writes a file `all_precip.nc`

```{bash}
cd ~/Documents/Heliconia-Drought/data_raw/XavierUT

cdo sellonlatbox,-60.167,-59.583,-2.5,-2.25 prec_daily_UT_Brazil_v2.1_19800101_19891231.nc 1980_1989.nc
cdo sellonlatbox,-60.167,-59.583,-2.5,-2.25 prec_daily_UT_Brazil_v2.1_19900101_19991231.nc 1990_1999.nc
cdo sellonlatbox,-60.167,-59.583,-2.5,-2.25 prec_daily_UT_Brazil_v2.1_20000101_20091231.nc 2000_2009.nc
cdo sellonlatbox,-60.167,-59.583,-2.5,-2.25 prec_daily_UT_Brazil_v2.1_20100101_20151231.nc 2010_2015.nc

cdo -O mergetime 1980_1989.nc 1990_1999.nc 2000_2009.nc 2010_2015.nc all_precip.nc
rm 1980_1989.nc 1990_1999.nc 2000_2009.nc 2010_2015.nc
```

### ETo

Repeat with evapotranspirtation

```{bash}
cd ~/Documents/Heliconia-Drought/data_raw/XavierUT

cdo sellonlatbox,-60.167,-59.583,-2.5,-2.25 ETo_daily_UT_Brazil_v2_19800101_19891231.nc 1900_1989.nc
cdo sellonlatbox,-60.167,-59.583,-2.5,-2.25 ETo_daily_UT_Brazil_v2_19900101_19991231.nc 1990_1999.nc
cdo sellonlatbox,-60.167,-59.583,-2.5,-2.25 ETo_daily_UT_Brazil_v2_20000101_20061231.nc 2000_2006.nc
cdo sellonlatbox,-60.167,-59.583,-2.5,-2.25 ETo_daily_UT_Brazil_v2_20070101_20131231.nc 2007_2013.nc
cdo sellonlatbox,-60.167,-59.583,-2.5,-2.25 ETo_daily_UT_Brazil_v2_20140101_20170731.nc 2014_2017.nc

cdo -O mergetime 1900_1989.nc 1990_1999.nc 2000_2006.nc 2007_2013.nc 2014_2017.nc all_eto.nc
rm 1900_1989.nc 1990_1999.nc 2000_2006.nc 2007_2013.nc 2014_2017.nc
```

```{bash}
cd ~/Documents/Heliconia-Drought/data_raw/XavierUT

cdo -O merge all_precip.nc all_eto.nc precip_eto.nc
```
```{r}
# nc_open(here("data_raw", "XavierUT", "precip_eto.nc"))
```


## Tidy

```{r}
xa_all <- nc_open(here("data_raw", "XavierUT", "precip_eto.nc"))

time <- ncvar_get(xa_all, "time") #hours since 1980-01-01 12:00:00
time <- as_date(time/24, origin = ymd("1980-01-01"))

prec <- ncvar_get(xa_all, "prec")
eto <- ncvar_get(xa_all, "ETo")
dim(prec)

dimnames(eto) <- dimnames(prec) <- list(ncvar_get(xa_all, "longitude"),
                       as.character(time))

xa_precip <-
  t(prec) %>% #gotta do this because dates aren't unique and can't be colnames
  as_tibble(rownames = "date") %>% 
  pivot_longer(-date, names_to = "lon", values_to = "precip") 

xa_eto <-
  t(eto) %>% #gotta do this because dates aren't unique and can't be colnames
  as_tibble(rownames = "date") %>% 
  pivot_longer(-date, names_to = "lon", values_to = "eto")

xa_clim <-
  full_join(xa_precip, xa_eto, by = c("date", "lon")) %>% 
  add_column(lat = ncvar_get(xa_all, "latitude")) %>% 
  mutate(date = ymd(date), lon = as.numeric(lon)) %>% 
  select(date, lat, lon, precip, eto)
```

```{r}
write_csv(xa_clim, here("data_cleaned", "xavier_daily_0.25x0.25.csv"))
```





