---
title: "Wrangling Precipitation Data"
author: "Eric R. Scott"
date: "2020-06-24"
output: 
  html_notebook: 
    highlight: kate
    theme: yeti
    toc: yes
    toc_float: yes
    number_sections: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(here)
library(conflicted)
library(readxl)
library(lubridate)
library(janitor)
library(hms)
conflict_prefer("filter", "dplyr")
conflict_prefer("lag", "dplyr")
```

*Last compiled: `r Sys.Date()`*

# Purpose

Reading and wrangling precip data

# Reading and parsing data

The HORA column is sometimes formatted as text and sometimes as time.  Read in both ways and join.

```{r data, echo=TRUE}
sites <- list.files(here("data_raw", "rain"))
names(sites) <- str_remove(sites, "\\..+$")

all_raw <- map_df(sites, ~{
  site <- .x
  sheets <- excel_sheets(here("data_raw", "rain", site))
  sheets <- sheets[str_detect(sheets, "\\d{4}")]

  site_raw <-
    map_df(sheets, ~ read_excel(
      here("data_raw", "rain", site),
      sheet = .x,
      range = cell_limits(c(3,1), c(NA, 6)),
      col_types = c("date", "numeric", "text", "numeric", "text", "text")
    ))

time_as_date <-
  map_df(sheets, ~ suppressWarnings(read_excel(
    here("data_raw", "rain", site),
    sheet = .x,
    range = cell_limits(c(3,1), c(NA, 6)),
    col_types = c("date", "numeric", "text", "numeric", "date", "text")
  )))

site_raw <- site_raw %>% add_column(time_as_date = time_as_date$HORA)
},
.id = "site")
sample_n(all_raw, 7)
```

## Data Dictionary

There are 8 sites, each with a .xls spreadsheet with multiple tabs.  Each tab contains data from 3 years and the last two tabs have some aggregated data done in Excel.

- `DATA`: Date
- `CHUVA`: Rainfall in mm (?)
- `OBSERVADOR`: the name of the person who recorded the data
- `DIA`: day of year
- `HORA`: time of collection in 24-hr time  (sometimes as text, sometimes as time)
- `COMMENTARIO`: notes.  For example, whether the data was aggregated over previous days because no one was around to check the gauge.



# Cleaning

## Basics

- Remove missing rows
- Make column headings lowercase

```{r}
all <- 
  all_raw %>% 
  clean_names() %>% 
  filter(!is.na(data))
```


## Quality Control

### Check that there are no missing dates

This might actually be easier to do before merging all sites into one df.  Might want to keep as a list until the very end?  Or maybe can do with a `group(site)`?

```{r}
#TODO
```

- Check that `DIA` matches day of year calculated from date.

### Check times

For the HORA column in Excel, sometimes the entry is character and sometimes it is a time.  When `read_excel` uses "text", then the character entries read in correctly, but the time entries read in as a weird decimal number.  When `read_excel()` uses "date", then the character entries read in as `<NA>` and the time entries read in as the correct time, but on the date 1899-12-31. There are also some text entries of time that include notes, for example, "7:00    chuva noite<0,1", or are entirely notes, e.g. "nao foi feita observ". 

1. Extract notes and times separately from the `hora` column.
2. Convert the `hora` column to time
3. Merge and remove columns so there is `time` and `time_notes` left.

- get rid of "time_notes" if it was read in as datetime.  I.e. only do this note extraction for times read in as text.

```{r}
all_2 <- 
  all %>% 
  mutate(time_notes = str_remove(hora, "\\d{1,2}:\\d{2}"), #everything except times
         hora = str_replace(hora, "(?<=\\d{1,2});(?=\\d{2})", ":"), #fix semi-colon typos
         time = parse_hm(str_extract(hora, "\\d{1,2}:\\d{2}"))) %>% #convert to time
  mutate(time_notes = ifelse(!is.na(time_as_date), NA, time_notes), #get rid of notes that shouldn't be there
         time_notes = na_if(time_notes, "")) %>% 
  mutate(time_as_date = as_hms(time_as_date)) %>% #merge two times
  mutate(time = as_hms(ifelse(!is.na(time_as_date), time_as_date, time)))
```

Check that you got them all by comparing original data read in both ways to new time column and look for NAs.

```{r}
all_2 %>% 
  filter(!is.na(hora) & is.na(time))
```

**manually fix these errors??**


Get rid of unused columns

```{r}
all_clean <-
  all_2 %>% 
  select(site, data, chuva, observador, dia, time, time_notes, comentario)
all_clean
```

## Annotate and tidy

### Check / mark accumulated data

After no one uses a site for a while, the next observation is accumulated.  Sometimes it is marked as such in the comments, but not always.  Other times, the site has maybe not been used for over a month and the next observation doesn't seem like it is accumulated.  I'm not sure the best way to deal with this right now.

```{r}
unique(all_clean$site)
all_clean2 <-
  all_clean %>% 
  group_by(site) %>% 
  #anything observation preceded by an NA note as "Accumulated"
  mutate(accumulated = ifelse(is.na(lag(chuva, default = 1)) & !is.na(chuva), "accumulated", NA)) %>%
  #remove missing observations
  filter(!is.na(chuva))

# E.g. at this site there are long stretches of NAs followed by low precip values.
all_clean2 %>% 
  # filter(!is.na(comentario) & !comentario %in% c("Acumulado", "acumulada", "acumulado") ) %>%
  filter(site == "COLOSSO") %>%
  View()
```




